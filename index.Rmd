---
title: "Final-Project"
subtitle: "Predicting and Classificating Question Score"
author: "Alfredo Quintana - Miguel Porro "
output: 
     prettydoc::html_pretty:
         theme: cayman
        

---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r  include=FALSE, cache=TRUE}
source("score_classification.R")
source("exploratory_analysis.R")
source("closed_classification.R")
```

```{r  include=FALSE, cache=TRUE}
source("score_regression.R")

```

## **Introducción y Motivación**

El desarrollo integral del estudiante de matemática se basa en la investigación y recopilación de
información adicional a la estudiada en clases, llegar a profundizar un tema puede ser muy sencillo
hoy en día con el acceso a internet, pero a medida que el estudiante avanza en su carrera empieza a
dificultarse la búsqueda y recopilación de información dado a la complejidad de las asignaturas, en algunos casos surgen
problemas de mayor dificultad que obligan a buscar ayuda profesional y en este caso salen a relucir
sites o foros donde personas del área comparten dudas y conocimiento, en particular está el caso de
[math.stackexchange.com](https://math.stackexchange.com), en el cual tanto profesores y alumnos participan en dicho intercambio de
información. Este website resulta
una herramienta útil para todo tipo de personas, además, es publica, gratuita y de fácil manejo, en él
se hacen en promedio dos preguntas por minuto, y el tiempo promedio en obtener una respuesta es
de 10 min, lo cual lo convierte en una fuente confiable para obtener respuestas a dudas emergentes, al
menos para quien busca tener una idea de hacia dónde va dirigido el problema. Con mas de 1.372.2971
preguntas y mas de 7.015.119 usuarios, [math.stackexchange.com](https://math.stackexchange.com) se ha convertido en una herramienta útil no solo para estudiantes de matemáticas puras si no para cualquier estudiante cuya carrera este ligada con esta ciencia.  

El equipo esta interesado en determinar a traves de modelos de clasificacion y mineria de texto, si una pregunta hecha en el sitio tiene probabilidades de ser cerrada luego de una revision, ya sea por estar mal redact5ada, ser un duplicado de otra pregunta, etc. Además se quiere predecir el Score de una pregunta, la idea es identificar preguntas con baja calidad y hacer seguimiento de las mismas.

## **Los Datos**

El proceso de obtencion de los datos se realizo mediante el uso de la [**API**](https://api.stackexchange.com/) de stackexchange.com y la biblioteca **stackr** desarrollada por [David Robinson](https://github.com/dgrtwo), todo el codigo y documentacion asociada se encuentra en el siguiente enlace [**StackMath**](https://github.com/Qalfredo/stackmath). 
Inicialmente hacemos un llamado a la API para obtener la informacion general del sitio a traves de la funcion **stack_info()**:

```{r  echo = FALSE }
library(knitr)
kable(informacion)

```

Toda la manipulacion y limpieza de los datos se hizo usando las bibliotecas dplyr,tm,stringr. Se transformo el cuerpo de texto de cada pregunta en texto tratable: se eliminaron los signos de puntuacion, se removieron los numeros y palabras que no aportan informacion al modelo (stopwords). el resultado del preprocesamiento es una matris Termino-Documento, la funcion peso que consideramos fue TF-IDF Weight:


```{r  echo = FALSE }
library(knitr)
kable(questions_mining[1:5,1:8])

```

Puede observarse en la tabla anterior que en el caso de la tarea de clasificación fue necesario discretizar la variable "score", usamos el siguiente criterio:
$$ score>0 \Rightarrow score = 1$$
$$ score<0 \Rightarrow score = -1$$
$$ score = 0 \Rightarrow score = 0$$



## **Análisis Exploratorio**

### Relaciones entre las variables númericas

```{r  echo=FALSE}
library(ggplot2)
layout(matrix(c(1,1,2,3), 2, 2, byrow = TRUE))
 ggplot(questions, aes(x = questions$score, y = questions$view_count)) + geom_point(size = 0.9, aes(colour = factor(questions$is_answered)) ) + xlab("Score") + ylab("Visualizaciones") + scale_color_discrete(name= "Respuesta válida")

ggplot(questions, aes(x = questions$answer_count, y = questions$score)) + geom_point(size = 0.9, aes(colour = factor(questions$is_answered)) ) + xlab("Respuestas") + ylab("Score") + scale_color_discrete(name = "Respuesta válida")


 ggplot(cloo, aes(x = cloo$score, y = cloo$view_count)) + geom_point(size = 3, aes(colour = factor(cloo$is_closed)) , alpha =0.3) + ylab ("Visualizaciones") + xlab("Score") + scale_color_discrete(name= "Cerrada")



```


#### Tags mas frecuentes en el sitio y nube de palabras
```{r  echo=FALSE}
library(wordcloud2)
nube
grafico.1

```

### Tags mas frecuentes dentro de las 10,000 preguntas

```{r  echo=FALSE}
library(ggplot2)
 ggplot(freq.terms.dataframe, aes(x = freq_terms,y = f)) + geom_bar(stat = "identity",  width = 0.5) + coord_flip() + xlab("Tags") + ylab("Frecuency") 
```


### Comparación entre preguntas con respuesta válida y  sin respuesta


```{r  echo=FALSE, message=FALSE}
library(ggplot2)
ggplot(questions,aes(x = is_answered)) + geom_histogram(stat = "count", width = 0.5) + xlab("Is answered") + ylab("Frequency")

```

### ¿ Cuál es el Tag mas frecuente dentro de las preguntas sin respuesta ?

El análisis muestra que en el 2015 el Tag mas frecuente dentro de las preguntas sin respuesta valida es "probability"

```{r  echo=FALSE, message=FALSE}
library(ggplot2)
ggplot(freq.terms.noadataframe, aes(x = freq_noa_terms,y = f_noa)) + geom_bar(stat = "identity",  width = 0.3) + coord_flip() + xlab("Tags") + ylab("Frecuency")

```

## Exploración mediante series temporales 


  

#  **Machine Learning**
Para esta tarea se realizo el tratamiento de los datos antes descrito y además se uso una division del conjunto de datos en subconjunto de entrenamiento (70%) y subconjunto de prueba (30%).

#### Métricas para la evaluación del rendimiento de los modelos

$$Sensitivity= \dfrac{TP}{TP+FN}$$

$$Specificity = \dfrac{TN}{TN+FP} $$
$$Accuracy = \dfrac{TP+FN}{TP+FN+TN+FP} $$
$$RMSE = \sqrt{\dfrac{1}{N}\sum (Obs-Pred)^2} $$


## Clasificación de preguntas según el Score:

Se tomaron en cuenta dos algoritmos de clasificación:

 - SVM (Support Vector Machine)
 - NaiveBayes ( Naive Bayes Ingenuo)



```{r  echo=TRUE, message=FALSE, cache=TRUE}
library(e1071)

model.svm 


pred.svm = predict(model.svm, question.testing)


table(question.testing$score,pred.svm,dnn=c("Obs","Pred"))
```



```{r  echo=TRUE, message=FALSE, cache=TRUE}
library(e1071)

train <- sample(1:10000,7000)
test <- sample(c(1:10000)[-train],3000)
naive.questions <- naiveBayes(x= as.matrix(questions_dtm)[train,], y = questions_mining$score[train])

pp <- predict(naive.questions,question.testing) 



table(pp, questions_mining$score[test],dnn=c("Obs","Pred")) 

```

## Predicción del Score de una pregunta

Se tomo en cuenta el algoritmo svm como máquina de regresión.


```{r  echo=TRUE, message=FALSE, cache=TRUE}
library(e1071)

model.svr 


```

```{r  echo=TRUE, message=FALSE, cache=TRUE}

rmse <- function(error)
{
  sqrt(mean(error^2))
}
rmse(error)


```

Además de considerar el RSME como medida de rendimiento del modelo, en este caso establecimos que un margen optimo para nuestro problema es de 1.5, es decrir, $$ |error|\leq 1.5.$$
Con un cálculo bastante sencillo se concluye que el modelo "predice" el Score de una pregunta dentro de este margen en un 79.5% de los casos.
```{r  echo=TRUE, message=FALSE}

count = 0
for(i in 1:600){
  if (abs(error[i]) <= 1.5){count = count + 1}else{count = count}
}
count 


```


## Clasificación de preguntas Cerradas

Se tomaron en cuenta 3 algoritmos de clasificacion:
-SVM (Support Vector Machine)
-NaiveBayes (Naive Bayes Ingenuo)
-C5.0 (Arbol de Decisión)


```{r  echo=TRUE, message=FALSE, cache=TRUE}

 train.sample <- sample(1:1189,832)
 test.sample <- sample(c(1:1189)[-train.sample],357)

closed.svm

table(pred.test,vector.class[test.sample])



```



```{r  echo=TRUE, message=FALSE}

 ## tree.model <- C5.0(x= closed.training, y = as.factor(vector.class[train.sample]), trials = 20)
table(p ,as.factor(vector.class[test.sample]))



```



```{r  echo=TRUE, message=FALSE, cache=TRUE}


# naive.closed.model <- naiveBayes(x = closed.training , y = vector.class[train.sample] , data = closed.train)

table(p1, vector.class.2[test.sample])


```








